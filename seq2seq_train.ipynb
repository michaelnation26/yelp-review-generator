{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq_train.ipynb","provenance":[{"file_id":"1Ekd5pUeCX7VOrMx94_czTkwNtLN32Uyu","timestamp":1618536395439},{"file_id":"1WIk2bxglElfZewOHboPFNj8H44_VAyKE","timestamp":1604335169955},{"file_id":"19wkOLQIjBBXQ-j3WWTEiud6nGBEw4MdF","timestamp":1599818368238}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dD_wx7MhMkAg"},"source":["Use this notebook in [Google Colab](https://drive.google.com/file/d/1BsMFZBG7QhGyXBTO-8BWQRkX4gqcJ7Cb/view?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"Nr0tinBfKDvt"},"source":["#### Resources\n","\n","[HuggingFace BERT2BERT Tutorial](https://colab.research.google.com/drive/1Ekd5pUeCX7VOrMx94_czTkwNtLN32Uyu?usp=sharing)\n","\n","[Yelp Open Dataset Documentation](https://www.yelp.com/dataset/documentation/main)"]},{"cell_type":"markdown","metadata":{"id":"5RGGx-_8JpWE"},"source":["#### Next two cells are only needed when using Google Colab."]},{"cell_type":"code","metadata":{"id":"WpN68sAUPNcS"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPdvGjOrPN-f"},"source":["# change this to your project directory\n","%cd \"drive/MyDrive/CodingProjects/yelp_review_generator\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w67vkz3KP9eZ"},"source":["%%capture\n","!pip install datasets==1.5.0\n","!pip install transformers==4.5.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twD4iLTsOEnP"},"source":["import json\n","import random\n","from typing import Dict, List\n","\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer, \n","    EncoderDecoderConfig, \n","    EncoderDecoderModel, \n","    Seq2SeqTrainer, \n","    Seq2SeqTrainingArguments\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TFr8m2GXLKNF"},"source":["Before continuing, download the [Yelp Open Dataset](https://www.yelp.com/dataset). After decompressing the zip file, the folder should be called `yelp_dataset` and placed in the root directory of this project."]},{"cell_type":"code","metadata":{"id":"ItEpgBeYOEnP"},"source":["FILEPATH_BUSINESS = \"yelp_dataset/yelp_academic_dataset_business.json\"\n","FILEPATH_REVIEW = \"yelp_dataset/yelp_academic_dataset_review.json\"\n","FILEPATH_USER = \"yelp_dataset/yelp_academic_dataset_user.json\"\n","\n","PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n","TRAINED_MODEL_OUTPUT_DIR = \"model\"\n","\n","BATCH_SIZE = 16\n","ENCODER_MAX_LEN = 32\n","DECODER_MAX_LEN = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dgthhQlbOEnQ"},"source":["## Tokenizer"]},{"cell_type":"code","metadata":{"id":"sgTiC0rhMb7C"},"source":["tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","tokenizer.bos_token = tokenizer.cls_token\n","tokenizer.eos_token = tokenizer.sep_token"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1X82_HyOEnR"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"qLYqHFh6UK_o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619826591249,"user_tz":240,"elapsed":4403,"user":{"displayName":"Michael N.","photoUrl":"https://lh5.googleusercontent.com/-bIpqbmaPLJc/AAAAAAAAAAI/AAAAAAAAD2Q/F36Fk-FNfMA/s64/photo.jpg","userId":"13752494364938472639"}},"outputId":"5a742122-0c3c-4130-9c19-e91da2e039b6"},"source":["businesses = {}\n","with open(FILEPATH_BUSINESS, 'r') as f:\n","    for line in f:\n","        business = json.loads(line)\n","        if business[\"categories\"] and 5 < business[\"review_count\"] < 40:\n","            # categories is stored as a comma separated str. Convert to a list.\n","            categories_list = business[\"categories\"].split(\", \")\n","            \n","            businesses[business[\"business_id\"]] = {\n","                \"name\": business[\"name\"],\n","                \"city\": business[\"city\"],\n","                \"categories\": categories_list\n","            }\n","\n","print(f\"num businesses: {len(businesses)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["num businesses: 102635\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qPgO9GMVYhjM"},"source":["users = {}\n","with open(FILEPATH_USER, 'r') as f:\n","    for line in f:\n","        user = json.loads(line)\n","        # \"elite\" is a str composed of years separated by commas. e.g. \"2004,2005\"\n","        # \"elite_level\" is equivalent to the total number of years\n","        elite_level = len(user[\"elite\"].split(\",\")) if user[\"elite\"] else 0\n","        users[user[\"user_id\"]] = {\"elite_level\": elite_level}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSJnsRr5OEnR"},"source":["reviews = {\"input_text\": [], \"output_text\": []}\n","with open(FILEPATH_REVIEW, 'r') as f:\n","    for line in f:\n","        review = json.loads(line)\n","        if review[\"business_id\"] in businesses:\n","            business = businesses[review[\"business_id\"]]\n","            user = users[review[\"user_id\"]]\n","            \n","            # shuffle categories each time to prevent model from memorizing order\n","            random.shuffle(business[\"categories\"])\n","            categories_str = \", \".join(business[\"categories\"])\n","            \n","            input_text = (\n","                f\"stars {int(review['stars'])}\"\n","                f\"; funny {review['funny']}\"\n","                f\"; elite level {user['elite_level']}\"\n","                f\"; name {business['name']}\"\n","                f\"; city {business['city']}\"\n","                f\"; categories {categories_str}\"\n","            )\n","            reviews[\"input_text\"].append(input_text)\n","            \n","            # trim off excess tokens to reduce memory\n","            output_tokens = review[\"text\"].split()[:DECODER_MAX_LEN]\n","            output_text = \" \".join(output_tokens)\n","            reviews[\"output_text\"].append(output_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlRTDHb1OEnS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619826785202,"user_tz":240,"elapsed":191716,"user":{"displayName":"Michael N.","photoUrl":"https://lh5.googleusercontent.com/-bIpqbmaPLJc/AAAAAAAAAAI/AAAAAAAAD2Q/F36Fk-FNfMA/s64/photo.jpg","userId":"13752494364938472639"}},"outputId":"a59587c6-e074-48c9-d47f-d0cf3ce4b57e"},"source":["ds = Dataset.from_dict(reviews)\n","ds = ds.train_test_split(train_size=0.95)\n","train_ds, val_ds = ds[\"train\"], ds[\"test\"]\n","ds"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_text', 'output_text'],\n","        num_rows: 1565192\n","    })\n","    test: Dataset({\n","        features: ['input_text', 'output_text'],\n","        num_rows: 82379\n","    })\n","})"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"yoN2q0hZUbXN"},"source":["def process_data_to_model_inputs(batch):\n","    # tokenize the inputs and labels\n","    inputs = tokenizer(\n","        batch[\"input_text\"], padding=\"max_length\", truncation=True, max_length=ENCODER_MAX_LEN\n","    )\n","    outputs = tokenizer(\n","        batch[\"output_text\"], padding=\"max_length\", truncation=True, max_length=DECODER_MAX_LEN\n","    )\n","\n","    batch[\"input_ids\"] = inputs.input_ids\n","    batch[\"attention_mask\"] = inputs.attention_mask\n","    batch[\"decoder_input_ids\"] = outputs.input_ids\n","    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n","    batch[\"labels\"] = outputs.input_ids.copy()\n","\n","    # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n","    # We have to make sure that the PAD token is ignored\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in labels] \n","        for labels in batch[\"labels\"]\n","    ]\n","\n","    return batch\n","\n","train_ds = train_ds.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=64,\n","    remove_columns=[\"input_text\", \"output_text\"]\n",")\n","\n","train_ds.set_format(\n","    type=\"torch\", \n","    columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")\n","\n","val_ds = val_ds.map(\n","    process_data_to_model_inputs, \n","    batched=True, \n","    batch_size=64,\n","    remove_columns=[\"input_text\", \"output_text\"]\n",")\n","\n","val_ds.set_format(\n","    type=\"torch\", \n","    columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aEjb026cNC38"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"tS0UndNoQh8t","scrolled":true},"source":["enc_dec_model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n","    PRETRAINED_MODEL_NAME, PRETRAINED_MODEL_NAME\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JD2jv3GkyjR-"},"source":["# set special tokens\n","enc_dec_model.config.decoder_start_token_id = tokenizer.bos_token_id\n","enc_dec_model.config.eos_token_id = tokenizer.eos_token_id\n","enc_dec_model.config.pad_token_id = tokenizer.pad_token_id\n","\n","# sensible parameters for beam search\n","enc_dec_model.config.vocab_size = enc_dec_model.config.decoder.vocab_size\n","enc_dec_model.config.max_length = DECODER_MAX_LEN\n","enc_dec_model.config.no_repeat_ngram_size = 3\n","enc_dec_model.config.early_stopping = True\n","enc_dec_model.config.length_penalty = 2.0\n","enc_dec_model.config.top_p = 0.95\n","enc_dec_model.config.do_sample = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u98CLZiTkgzv"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"LAaTxUpdzshF"},"source":["# set training arguments - these params are not really tuned, feel free to change\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=TRAINED_MODEL_OUTPUT_DIR,\n","    save_total_limit=2,\n","    overwrite_output_dir=True,\n","    save_steps=5000,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    evaluation_strategy=\"steps\",\n","    logging_steps=5000,\n","    logging_first_step=True,\n","    warmup_ratio=0.05,\n","    num_train_epochs=1,\n","    fp16=True\n",")\n","\n","# instantiate trainer\n","trainer = Seq2SeqTrainer(\n","    model=enc_dec_model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    train_dataset=train_ds,\n","    eval_dataset=val_ds\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAnQwQXbOEnU"},"source":["trainer.train()"],"execution_count":null,"outputs":[]}]}